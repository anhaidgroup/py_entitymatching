{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This quickstart guide explains how to match two tables using Magellan. Our goal is to come up with a workflow to match DBLP and ACM datasets. Specifically, we want to achieve precision greater than 95% and get recall as high as possible. The datasets contain information about the conference papers published in top databse conferences.\n",
    "\n",
    "First, we need to import the Magellan package as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import py_entitymatching as em\n",
    "import pandas as pd\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version: 3.6.3 |Anaconda custom (64-bit)| (default, Oct 13 2017, 12:02:49) \n",
      "[GCC 7.2.0]\n",
      "pandas version: 0.21.0\n",
      "magellan version: 0.2.0\n"
     ]
    }
   ],
   "source": [
    "print('python version: ' + sys.version )\n",
    "print('pandas version: ' + pd.__version__ )\n",
    "print('magellan version: ' + em.__version__ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching two tables typically consists of the following three steps:\n",
    "1. Loading the input tables\n",
    "2. Blocking the input tables to get a candidate set\n",
    "3. Matching the tuple pairs in the candidate set\n",
    "\n",
    "# 1. Loading the input tables\n",
    "\n",
    "We begin by loading the input tables. For the purpose of this guide, we use the datasets that are included with the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dblp_dataset_path = os.sep.join(['DBLP_ACM', 'DBLP_cleaned.csv'])\n",
    "#acm_dataset_path = os.sep.join(['DBLP_ACM', 'ACM_cleaned.csv'])\n",
    "\n",
    "datasets_dir = em.get_install_path() + os.sep + 'datasets'\n",
    "\n",
    "dblp_dataset_path = datasets_dir + os.sep + 'DBLP.csv'\n",
    "acm_dataset_path = datasets_dir + os.sep + 'ACM.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metadata file is not present in the given path; proceeding to read the csv file.\n",
      "Metadata file is not present in the given path; proceeding to read the csv file.\n"
     ]
    }
   ],
   "source": [
    "# Load csv files as dataframes and set the key attribute in the dataframe\n",
    "A = em.read_csv_metadata(dblp_dataset_path, key='id')\n",
    "B = em.read_csv_metadata(acm_dataset_path, key='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tuples in A: 2616\n",
      "Number of tuples in B: 2294\n",
      "Number of tuples in A X B (i.e the cartesian product): 6001104\n"
     ]
    }
   ],
   "source": [
    "print('Number of tuples in A: ' + str(len(A)))\n",
    "print('Number of tuples in B: ' + str(len(B)))\n",
    "print('Number of tuples in A X B (i.e the cartesian product): ' + str(len(A)*len(B)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>journals/sigmod/Mackay99</td>\n",
       "      <td>Semantic Integration of Environmental Models for Application to Global Information Systems and D...</td>\n",
       "      <td>D. Scott Mackay</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>1999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conf/vldb/PoosalaI96</td>\n",
       "      <td>Estimation of Query-Result Distribution and its Application in Parallel-Join Load Balancing</td>\n",
       "      <td>Viswanath Poosala, Yannis E. Ioannidis</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>1996.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0  journals/sigmod/Mackay99   \n",
       "1      conf/vldb/PoosalaI96   \n",
       "\n",
       "                                                                                                 title  \\\n",
       "0  Semantic Integration of Environmental Models for Application to Global Information Systems and D...   \n",
       "1          Estimation of Query-Result Distribution and its Application in Parallel-Join Load Balancing   \n",
       "\n",
       "                                  authors          venue    year  \n",
       "0                         D. Scott Mackay  SIGMOD Record  1999.0  \n",
       "1  Viswanath Poosala, Yannis E. Ioannidis           VLDB  1996.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>304586</td>\n",
       "      <td>The WASA2 object-oriented workflow management system</td>\n",
       "      <td>Gottfried Vossen, Mathias Weske</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>304587</td>\n",
       "      <td>A user-centered interface for querying distributed multimedia databases</td>\n",
       "      <td>Isabel F. Cruz, Kimberly M. James</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  \\\n",
       "0  304586   \n",
       "1  304587   \n",
       "\n",
       "                                                                     title  \\\n",
       "0                     The WASA2 object-oriented workflow management system   \n",
       "1  A user-centered interface for querying distributed multimedia databases   \n",
       "\n",
       "                             authors  \\\n",
       "0    Gottfried Vossen, Mathias Weske   \n",
       "1  Isabel F. Cruz, Kimberly M. James   \n",
       "\n",
       "                                            venue  year  \n",
       "0  International Conference on Management of Data  1999  \n",
       "1  International Conference on Management of Data  1999  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('id', 'id')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the key attributes of table A and B.\n",
    "em.get_key(A), em.get_key(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# If the tables are large we can downsample the tables like this\n",
    "A1, B1 = em.down_sample(A, B, 500, 1)\n",
    "# But for the demo, we will use the entire table A and B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Blocking to create candidate tuple pairs\n",
    "\n",
    "Before we do the matching, we would like to remove the obviously non-matching tuple pairs from the input tables. This would reduce the number of tuple pairs considered for matching.\n",
    "\n",
    "Magellan provides four different blockers: (1) attribute equivalence, (2) overlap, (3) rule-based, and (4) black-box. Refer to [api reference] for more details. The user can mix and match these blockers to form a blocking sequence applied to input tables.\n",
    "\n",
    "For the matching problem at hand, we know that two conference papers published in different years cannot match. So, we decide to apply an attribute equivelance blocker on the 'year' attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plan\n",
    "# A, B ------ attribute equivalence [year] -----> C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create attribute equivalence blocker\n",
    "ab = em.AttrEquivalenceBlocker()\n",
    "# Block tables using 'year' attribute: same year then include in the canidate set\n",
    "C1 = ab.block_tables(A, B, 'year', 'year', \n",
    "                   l_output_attrs=['title', 'authors', 'year'],\n",
    "                   r_output_attrs=['title', 'authors', 'year']\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "577024"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of rows in C1\n",
    "len(C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>ltable_id</th>\n",
       "      <th>rtable_id</th>\n",
       "      <th>ltable_title</th>\n",
       "      <th>ltable_authors</th>\n",
       "      <th>ltable_year</th>\n",
       "      <th>rtable_title</th>\n",
       "      <th>rtable_authors</th>\n",
       "      <th>rtable_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>journals/sigmod/Mackay99</td>\n",
       "      <td>304586</td>\n",
       "      <td>Semantic Integration of Environmental Models for Application to Global Information Systems and D...</td>\n",
       "      <td>D. Scott Mackay</td>\n",
       "      <td>1999</td>\n",
       "      <td>The WASA2 object-oriented workflow management system</td>\n",
       "      <td>Gottfried Vossen, Mathias Weske</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>journals/sigmod/Mackay99</td>\n",
       "      <td>304587</td>\n",
       "      <td>Semantic Integration of Environmental Models for Application to Global Information Systems and D...</td>\n",
       "      <td>D. Scott Mackay</td>\n",
       "      <td>1999</td>\n",
       "      <td>A user-centered interface for querying distributed multimedia databases</td>\n",
       "      <td>Isabel F. Cruz, Kimberly M. James</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id                 ltable_id  rtable_id  \\\n",
       "0    0  journals/sigmod/Mackay99     304586   \n",
       "1    1  journals/sigmod/Mackay99     304587   \n",
       "\n",
       "                                                                                          ltable_title  \\\n",
       "0  Semantic Integration of Environmental Models for Application to Global Information Systems and D...   \n",
       "1  Semantic Integration of Environmental Models for Application to Global Information Systems and D...   \n",
       "\n",
       "    ltable_authors ltable_year  \\\n",
       "0  D. Scott Mackay        1999   \n",
       "1  D. Scott Mackay        1999   \n",
       "\n",
       "                                                              rtable_title  \\\n",
       "0                     The WASA2 object-oriented workflow management system   \n",
       "1  A user-centered interface for querying distributed multimedia databases   \n",
       "\n",
       "                      rtable_authors rtable_year  \n",
       "0    Gottfried Vossen, Mathias Weske        1999  \n",
       "1  Isabel F. Cruz, Kimberly M. James        1999  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first two rows from C1\n",
    "C1.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of tuple pairs considered for matching is reduced to 601284 (from 6001104), but we would want to make sure that the blocker did not drop any potential matches. We could debug the blocker output in Magellan as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Debug blocker output\n",
    "dbg = em.debug_blocker(C1, A, B, output_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>ltable_id</th>\n",
       "      <th>rtable_id</th>\n",
       "      <th>ltable_title</th>\n",
       "      <th>ltable_authors</th>\n",
       "      <th>ltable_venue</th>\n",
       "      <th>rtable_title</th>\n",
       "      <th>rtable_authors</th>\n",
       "      <th>rtable_venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>journals/sigmod/KoubarakisTID03</td>\n",
       "      <td>945736</td>\n",
       "      <td>Selective information dissemination in P2P networks: problems and solutions</td>\n",
       "      <td>Stratos Idreos, Manolis Koubarakis, Christos Tryfonopoulos, Yannis Drougas</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>Selective information dissemination in P2P networks: problems and solutions</td>\n",
       "      <td>Manolis Koubarakis, Christos Tryfonopoulos, Stratos Idreos, Yannis Drougas</td>\n",
       "      <td>ACM SIGMOD Record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>journals/sigmod/LabrinidisR00</td>\n",
       "      <td>344794</td>\n",
       "      <td>Generating Dynamic Content at Database-Backed Web Servers: cgi-bin vs. mod_perl</td>\n",
       "      <td>Alexandros Labrinidis, Nick Roussopoulos</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>Generating dynamic content at database-backed web servers: cgi-bin vs. mod_perl</td>\n",
       "      <td>Alexandros Labrinidis, Nick Roussopoulos</td>\n",
       "      <td>ACM SIGMOD Record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>journals/sigmod/Chen94</td>\n",
       "      <td>187460</td>\n",
       "      <td>Database Research at NTHU and ITRI</td>\n",
       "      <td>Arbee L. P. Chen</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>Database research at NTHU and ITRI</td>\n",
       "      <td>Arbee L. P. Chen</td>\n",
       "      <td>ACM SIGMOD Record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>journals/sigmod/MedeirosP94</td>\n",
       "      <td>181566</td>\n",
       "      <td>Databases for GIS</td>\n",
       "      <td>Claudia Bauzer Medeiros, Fatima Pires</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>Databases for GIS</td>\n",
       "      <td>Claudia Bauzer Medeiros, Fatima Pires</td>\n",
       "      <td>ACM SIGMOD Record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>journals/sigmod/Kosch02</td>\n",
       "      <td>565123</td>\n",
       "      <td>MPEG-7 and Multimedia Database Systems</td>\n",
       "      <td>Harald Kosch</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>MPEG-7 and multimedia database systems</td>\n",
       "      <td>Harald Kosch</td>\n",
       "      <td>ACM SIGMOD Record</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id  similarity                        ltable_id  rtable_id  \\\n",
       "0    0    0.950000  journals/sigmod/KoubarakisTID03     945736   \n",
       "1    1    0.941176    journals/sigmod/LabrinidisR00     344794   \n",
       "2    2    0.923077           journals/sigmod/Chen94     187460   \n",
       "3    3    0.909091      journals/sigmod/MedeirosP94     181566   \n",
       "4    4    0.900000          journals/sigmod/Kosch02     565123   \n",
       "\n",
       "                                                                      ltable_title  \\\n",
       "0      Selective information dissemination in P2P networks: problems and solutions   \n",
       "1  Generating Dynamic Content at Database-Backed Web Servers: cgi-bin vs. mod_perl   \n",
       "2                                               Database Research at NTHU and ITRI   \n",
       "3                                                                Databases for GIS   \n",
       "4                                           MPEG-7 and Multimedia Database Systems   \n",
       "\n",
       "                                                               ltable_authors  \\\n",
       "0  Stratos Idreos, Manolis Koubarakis, Christos Tryfonopoulos, Yannis Drougas   \n",
       "1                                    Alexandros Labrinidis, Nick Roussopoulos   \n",
       "2                                                            Arbee L. P. Chen   \n",
       "3                                       Claudia Bauzer Medeiros, Fatima Pires   \n",
       "4                                                                Harald Kosch   \n",
       "\n",
       "    ltable_venue  \\\n",
       "0  SIGMOD Record   \n",
       "1  SIGMOD Record   \n",
       "2  SIGMOD Record   \n",
       "3  SIGMOD Record   \n",
       "4  SIGMOD Record   \n",
       "\n",
       "                                                                      rtable_title  \\\n",
       "0      Selective information dissemination in P2P networks: problems and solutions   \n",
       "1  Generating dynamic content at database-backed web servers: cgi-bin vs. mod_perl   \n",
       "2                                               Database research at NTHU and ITRI   \n",
       "3                                                                Databases for GIS   \n",
       "4                                           MPEG-7 and multimedia database systems   \n",
       "\n",
       "                                                               rtable_authors  \\\n",
       "0  Manolis Koubarakis, Christos Tryfonopoulos, Stratos Idreos, Yannis Drougas   \n",
       "1                                    Alexandros Labrinidis, Nick Roussopoulos   \n",
       "2                                                            Arbee L. P. Chen   \n",
       "3                                       Claudia Bauzer Medeiros, Fatima Pires   \n",
       "4                                                                Harald Kosch   \n",
       "\n",
       "        rtable_venue  \n",
       "0  ACM SIGMOD Record  \n",
       "1  ACM SIGMOD Record  \n",
       "2  ACM SIGMOD Record  \n",
       "3  ACM SIGMOD Record  \n",
       "4  ACM SIGMOD Record  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first few tuple pairs from the debug_blocker's output\n",
    "dbg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the debug blocker's output we observe that the current blocker drops quite a few potential matches. We would want to update the blocking sequence to avoid dropping these potential matches.\n",
    "\n",
    "For the considered dataset, we know that for the conference papers to match the author names must overlap between them. We could use overlap blocker for this purpose. Finally, we would want to union the outputs from the attribute equivalence blocker and the overlap blocker to get a consolidated candidate set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Updated blocking sequence\n",
    "# A, B ------ attribute equivalence [year] -----> C1--\n",
    "#                                                     |----> C\n",
    "# A, B ------ overlap blocker [authors] --------> C2--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Create an overlap blocker\n",
    "ob = em.OverlapBlocker()\n",
    "# Apply overlap blocker on 'authors' attribute\n",
    "C2 = ob.block_tables(A, B, 'authors', 'authors', \n",
    "                   l_output_attrs=['title', 'authors', 'year'],\n",
    "                   r_output_attrs=['title', 'authors', 'year']\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "316015"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of rows in C2\n",
    "len(C2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>ltable_id</th>\n",
       "      <th>rtable_id</th>\n",
       "      <th>ltable_title</th>\n",
       "      <th>ltable_authors</th>\n",
       "      <th>ltable_year</th>\n",
       "      <th>rtable_title</th>\n",
       "      <th>rtable_authors</th>\n",
       "      <th>rtable_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>journals/tods/LechtenborgerV03</td>\n",
       "      <td>304586</td>\n",
       "      <td>On the computation of relational view complements</td>\n",
       "      <td>Gottfried Vossen, Jens Lechtenbrger</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>The WASA2 object-oriented workflow management system</td>\n",
       "      <td>Gottfried Vossen, Mathias Weske</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>journals/sigmod/CherniakV03</td>\n",
       "      <td>304586</td>\n",
       "      <td>Reminiscences on Influential Papers</td>\n",
       "      <td>Mitch Cherniack, Kenneth A. Ross, Gottfried Vossen</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>The WASA2 object-oriented workflow management system</td>\n",
       "      <td>Gottfried Vossen, Mathias Weske</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id                       ltable_id  rtable_id  \\\n",
       "0    0  journals/tods/LechtenborgerV03     304586   \n",
       "1    1     journals/sigmod/CherniakV03     304586   \n",
       "\n",
       "                                        ltable_title  \\\n",
       "0  On the computation of relational view complements   \n",
       "1                Reminiscences on Influential Papers   \n",
       "\n",
       "                                       ltable_authors  ltable_year  \\\n",
       "0                 Gottfried Vossen, Jens Lechtenbrger       2003.0   \n",
       "1  Mitch Cherniack, Kenneth A. Ross, Gottfried Vossen       2003.0   \n",
       "\n",
       "                                           rtable_title  \\\n",
       "0  The WASA2 object-oriented workflow management system   \n",
       "1  The WASA2 object-oriented workflow management system   \n",
       "\n",
       "                    rtable_authors  rtable_year  \n",
       "0  Gottfried Vossen, Mathias Weske         1999  \n",
       "1  Gottfried Vossen, Mathias Weske         1999  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first two rows from C2\n",
    "C2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine blocker outputs\n",
    "C = em.combine_blocker_outputs_via_union([C1, C2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "860645"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of rows in the consolidated candidate set.\n",
    "len(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Debug again\n",
    "dbg = em.debug_blocker(C, A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>ltable_id</th>\n",
       "      <th>rtable_id</th>\n",
       "      <th>ltable_title</th>\n",
       "      <th>ltable_authors</th>\n",
       "      <th>ltable_venue</th>\n",
       "      <th>rtable_title</th>\n",
       "      <th>rtable_authors</th>\n",
       "      <th>rtable_venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>journals/sigmod/ACT-NET96</td>\n",
       "      <td>234896</td>\n",
       "      <td>ACT-NET - The Active Database Management System Manifesto: A Rulebase of ADBMS Features</td>\n",
       "      <td>?</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>The active database management system manifesto: a rulebase of ADBMS features</td>\n",
       "      <td>Corporate Act-Net Consortium</td>\n",
       "      <td>ACM SIGMOD Record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>conf/vldb/Team00</td>\n",
       "      <td>671838</td>\n",
       "      <td>High-Performance and Scalability through Application Tier,In-Memory Data Management</td>\n",
       "      <td>?</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>High-Performance and Scalability through Application Tier,In-Memory Data Management</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very Large Data Bases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>journals/sigmod/Dogac98</td>\n",
       "      <td>945727</td>\n",
       "      <td>Guest Editor's Introduction</td>\n",
       "      <td>Asuman Dogac</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>Guest editor's introduction</td>\n",
       "      <td>Karl Aberer</td>\n",
       "      <td>ACM SIGMOD Record</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id  similarity                  ltable_id  rtable_id  \\\n",
       "0    0    0.736842  journals/sigmod/ACT-NET96     234896   \n",
       "1    1    0.571429           conf/vldb/Team00     671838   \n",
       "2    2    0.500000    journals/sigmod/Dogac98     945727   \n",
       "\n",
       "                                                                              ltable_title  \\\n",
       "0  ACT-NET - The Active Database Management System Manifesto: A Rulebase of ADBMS Features   \n",
       "1      High-Performance and Scalability through Application Tier,In-Memory Data Management   \n",
       "2                                                              Guest Editor's Introduction   \n",
       "\n",
       "  ltable_authors   ltable_venue  \\\n",
       "0              ?  SIGMOD Record   \n",
       "1              ?           VLDB   \n",
       "2   Asuman Dogac  SIGMOD Record   \n",
       "\n",
       "                                                                          rtable_title  \\\n",
       "0        The active database management system manifesto: a rulebase of ADBMS features   \n",
       "1  High-Performance and Scalability through Application Tier,In-Memory Data Management   \n",
       "2                                                          Guest editor's introduction   \n",
       "\n",
       "                 rtable_authors           rtable_venue  \n",
       "0  Corporate Act-Net Consortium      ACM SIGMOD Record  \n",
       "1                           NaN  Very Large Data Bases  \n",
       "2                   Karl Aberer      ACM SIGMOD Record  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first few rows from the debugger output\n",
    "dbg.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the current blocker sequence does not drop obvious potential matches, and we can proceed with the matching step now. A subtle point to note here is, debugging blocker output practically provides a stopping criteria for modifying the blocker sequence.\n",
    "\n",
    "# 3. Matching tuple pairs in the candidate set\n",
    "\n",
    "In this step, we would want to match the tuple pairs in the candidate set. Specifically, we use learning-based method for matching purposes.\n",
    "\n",
    "This typically involves the following five steps:\n",
    "\n",
    "1. Sampling and labeling the candidate set\n",
    "2. Splitting the labeled data into development and evaluation set\n",
    "3. Selecting the best learning based matcher using the development set\n",
    "4. Evaluating the selected matcher using the evaluation set\n",
    "\n",
    "## 3.1 Sampling and labeling the candidate set\n",
    "\n",
    "First, we randomly sample 450 tuple pairs for labeling purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample candidate set\n",
    "S = em.sample_table(C, 450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we label the sampled candidate set. Specify we would enter 1 for a match and 0 for a non-match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Column name (gold) is not present in dataframe\n",
      "/u/p/m/pmartinkus/Documents/Research/py_entitymatching/py_entitymatching/gui/table_gui.py:94: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  table.set_value(idxv[i], cols[j], val)\n"
     ]
    }
   ],
   "source": [
    "# Label S and specify the attribute name for the label column\n",
    "L = em.label_table(S, 'gold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this guide, we will load in a pre-labeled dataset (of 415 tuple pairs) included in this package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metadata file is not present in the given path; proceeding to read the csv file.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "415"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-labeled data\n",
    "labeled_dataset_path = datasets_dir + os.sep + 'dblp_acm_demo_labels.csv'\n",
    "L = em.read_csv_metadata(labeled_dataset_path, \n",
    "                         key='_id',\n",
    "                         ltable=A, rtable=B, \n",
    "                         fk_ltable='ltable.id', fk_rtable='rtable.id')\n",
    "\n",
    "# Display the number of rows in the labaled data set\n",
    "len(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Splitting the labeled data into development and evaluation set\n",
    "\n",
    "In this step, we split the labeled data into two sets: development and evaluation. Specifically, the development set is used to come up with the best learning-based matcher and the evaluation set used to evaluate the selected matcher on unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the labeled data into development and evaluation set\n",
    "development_evaluation = em.split_train_test(L, train_proportion=0.7)\n",
    "development =  development_evaluation['train']\n",
    "evaluation = development_evaluation['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Select the best learning-based matcher\n",
    "\n",
    "Selecting the best learning-based matcher typically involves the following steps:\n",
    "\n",
    "1. Creating a set of learning-based matchers\n",
    "2. Creating features\n",
    "3. Extracting feature vectors\n",
    "4. Selecting the best learning-based matcher using k-fold cross validation\n",
    "5. Debugging the matcher (and possibly repeat the above steps)\n",
    "\n",
    "### 3.3.1 Creating a set of learning-based matchers\n",
    "\n",
    "First, we need to create a set of learning-based matchers. The following matchers are supported in Magellan: (1) decision tree, (2) random forest, (3) naive bayes, (4) svm, (5) logistic regression, and (6) linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a set of ML-matchers\n",
    "dt = em.DTMatcher(name='DecisionTree')\n",
    "svm = em.SVMMatcher(name='SVM')\n",
    "rf = em.RFMatcher(name='RF')\n",
    "nb = em.NBMatcher(name='NB')\n",
    "lg = em.LogRegMatcher(name='LogReg')\n",
    "ln = em.LinRegMatcher(name='LinReg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Creating features\n",
    "\n",
    "Next, we need to create a set of features for the development set. Magellan provides a way to automatically generate features based on the attributes in the input tables. For the purposes of this guide, we use the automatically generated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features\n",
    "feature_table = em.get_features_for_matching(A, B, validate_inferred_attr_types=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             title_title_jac_qgm_3_qgm_3\n",
       "1         title_title_cos_dlm_dc0_dlm_dc0\n",
       "2                         title_title_mel\n",
       "3                    title_title_lev_dist\n",
       "4                     title_title_lev_sim\n",
       "5         authors_authors_jac_qgm_3_qgm_3\n",
       "6     authors_authors_cos_dlm_dc0_dlm_dc0\n",
       "7                     authors_authors_mel\n",
       "8                authors_authors_lev_dist\n",
       "9                 authors_authors_lev_sim\n",
       "10                          year_year_exm\n",
       "11                          year_year_anm\n",
       "12                     year_year_lev_dist\n",
       "13                      year_year_lev_sim\n",
       "Name: feature_name, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the names of the features generated\n",
    "feature_table['feature_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select the year related features\n",
    "feature_subset_iter1 = feature_table[10:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10         year_year_exm\n",
       "11         year_year_anm\n",
       "12    year_year_lev_dist\n",
       "13     year_year_lev_sim\n",
       "Name: feature_name, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the names of the features selected\n",
    "feature_subset_iter1['feature_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 Extracting feature vectors\n",
    "\n",
    "In this step, we extract feature vectors using the development set and the created features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Extract feature vectors\n",
    "feature_vectors_dev = em.extract_feature_vecs(development, \n",
    "                            feature_table=feature_subset_iter1, \n",
    "                            attrs_after='gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>ltable.id</th>\n",
       "      <th>rtable.id</th>\n",
       "      <th>year_year_exm</th>\n",
       "      <th>year_year_anm</th>\n",
       "      <th>year_year_lev_dist</th>\n",
       "      <th>year_year_lev_sim</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>conf/sigmod/Chamberlin03</td>\n",
       "      <td>872877</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>180</td>\n",
       "      <td>conf/vldb/GoldmanSVG98</td>\n",
       "      <td>671346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>163</td>\n",
       "      <td>conf/vldb/ChaudhuriW00</td>\n",
       "      <td>671696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     _id                 ltable.id  rtable.id  year_year_exm  year_year_anm  \\\n",
       "31    31  conf/sigmod/Chamberlin03     872877            1.0            1.0   \n",
       "180  180    conf/vldb/GoldmanSVG98     671346            1.0            1.0   \n",
       "163  163    conf/vldb/ChaudhuriW00     671696            1.0            1.0   \n",
       "\n",
       "     year_year_lev_dist  year_year_lev_sim  gold  \n",
       "31                  2.0           0.666667     1  \n",
       "180                 2.0           0.666667     1  \n",
       "163                 2.0           0.666667     1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first few rows\n",
    "feature_vectors_dev.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we might have to impute the feature vectors as it might contain missing values. First, let us check if there are any missing values in the extracted feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the feature vectors contain missing values\n",
    "# A return value of True means that there are missing values\n",
    "any(pd.isnull(feature_vectors_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the extracted feature vectors contain missing values. We have to impute the missing values for the learning-based matchers to fit the model correctly. For the purposes of this guide, we impute the missing value in a column with the mean of the values in that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute feature vectors with the mean of the column values.\n",
    "feature_vectors_dev = em.impute_table(feature_vectors_dev, \n",
    "                exclude_attrs=['_id', 'ltable.id', 'rtable.id', 'gold'],\n",
    "                strategy='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4 Selecting the best matcher using cross-validation\n",
    "\n",
    "Now, we select the best matcher using k-fold cross-validation. For the purposes of this guide, we use five fold cross validation and use 'precision' metric to select the best matcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best ML matcher using CV\n",
    "result = em.select_matcher([dt, rf, svm, nb, lg, ln], table=feature_vectors_dev, \n",
    "        exclude_attrs=['_id', 'ltable.id', 'rtable.id', 'gold'],\n",
    "        k=10,\n",
    "        target_attr='gold', \n",
    "        metric_to_select_matcher='precision',\n",
    "        random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Matcher</th>\n",
       "      <th>Average precision</th>\n",
       "      <th>Average recall</th>\n",
       "      <th>Average f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.775601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.870943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.775601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.870943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.775601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.870943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.781584</td>\n",
       "      <td>0.970992</td>\n",
       "      <td>0.863488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.781584</td>\n",
       "      <td>0.970992</td>\n",
       "      <td>0.863488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>0.775601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.870943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Matcher  Average precision  Average recall  Average f1\n",
       "0  DecisionTree           0.775601        1.000000    0.870943\n",
       "1            RF           0.775601        1.000000    0.870943\n",
       "2           SVM           0.775601        1.000000    0.870943\n",
       "3            NB           0.781584        0.970992    0.863488\n",
       "4        LogReg           0.781584        0.970992    0.863488\n",
       "5        LinReg           0.775601        1.000000    0.870943"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['cv_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Matcher</th>\n",
       "      <th>Num folds</th>\n",
       "      <th>Fold 1</th>\n",
       "      <th>Fold 2</th>\n",
       "      <th>Fold 3</th>\n",
       "      <th>Fold 4</th>\n",
       "      <th>Fold 5</th>\n",
       "      <th>Fold 6</th>\n",
       "      <th>Fold 7</th>\n",
       "      <th>Fold 8</th>\n",
       "      <th>Fold 9</th>\n",
       "      <th>Fold 10</th>\n",
       "      <th>Mean score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>&lt;py_entitymatching.matcher.dtmatcher.DTMatcher object at 0x7f95caa34710&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.775601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>&lt;py_entitymatching.matcher.rfmatcher.RFMatcher object at 0x7f95caa347f0&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.775601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>&lt;py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0x7f95caa34748&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.775601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB</td>\n",
       "      <td>&lt;py_entitymatching.matcher.nbmatcher.NBMatcher object at 0x7f95caa34860&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.781584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0x7f95caa34908&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.781584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0x7f95caa34978&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.775601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  \\\n",
       "0  DecisionTree   \n",
       "1            RF   \n",
       "2           SVM   \n",
       "3            NB   \n",
       "4        LogReg   \n",
       "5        LinReg   \n",
       "\n",
       "                                                                            Matcher  \\\n",
       "0          <py_entitymatching.matcher.dtmatcher.DTMatcher object at 0x7f95caa34710>   \n",
       "1          <py_entitymatching.matcher.rfmatcher.RFMatcher object at 0x7f95caa347f0>   \n",
       "2        <py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0x7f95caa34748>   \n",
       "3          <py_entitymatching.matcher.nbmatcher.NBMatcher object at 0x7f95caa34860>   \n",
       "4  <py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0x7f95caa34908>   \n",
       "5  <py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0x7f95caa34978>   \n",
       "\n",
       "   Num folds    Fold 1    Fold 2    Fold 3    Fold 4    Fold 5  Fold 6  \\\n",
       "0         10  0.857143  0.807692  0.782609  0.777778  0.636364  0.6875   \n",
       "1         10  0.857143  0.807692  0.782609  0.777778  0.636364  0.6875   \n",
       "2         10  0.857143  0.807692  0.782609  0.777778  0.636364  0.6875   \n",
       "3         10  0.900000  0.807692  0.772727  0.777778  0.650000  0.6875   \n",
       "4         10  0.900000  0.807692  0.772727  0.777778  0.650000  0.6875   \n",
       "5         10  0.857143  0.807692  0.782609  0.777778  0.636364  0.6875   \n",
       "\n",
       "     Fold 7    Fold 8    Fold 9   Fold 10  Mean score  \n",
       "0  0.923077  0.714286  0.869565  0.700000    0.775601  \n",
       "1  0.923077  0.714286  0.869565  0.700000    0.775601  \n",
       "2  0.923077  0.714286  0.869565  0.700000    0.775601  \n",
       "3  0.920000  0.714286  0.863636  0.722222    0.781584  \n",
       "4  0.920000  0.714286  0.863636  0.722222    0.781584  \n",
       "5  0.923077  0.714286  0.869565  0.700000    0.775601  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['drill_down_cv_stats']['precision']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.5 Debugging matcher\n",
    "\n",
    "We observe that the best matcher is not getting us to the precision that we expect (i.e > 95%). We debug the matcher to see what might be wrong.\n",
    "\n",
    "To do this, first we split the feature vectors into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split feature vectors into train and test\n",
    "train_test = em.split_train_test(feature_vectors_dev, train_proportion=0.5)\n",
    "train = train_test['train']\n",
    "test = train_test['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug decision tree using GUI\n",
    "em.vis_debug_rf(rf, train, test, \n",
    "        exclude_attrs=['_id', 'ltable.id', 'rtable.id', 'gold'],\n",
    "        target_attr='gold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the GUI, we observe that using only 'year' related features result in a lot of false positives. So we decide to use all the features in the feature table (which had author, title and year related features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select all features from the feature table\n",
    "feature_subset_iter2 = feature_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we repeat extracting feature vectors (this time with updated feature table), imputing table and selecting the best matcher again using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Get new set of features\n",
    "feature_vectors_dev = em.extract_feature_vecs(development, feature_table=feature_subset_iter2, attrs_after='gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if imputation is required\n",
    "any(pd.isnull(feature_vectors_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute feature vectors\n",
    "feature_vectors_dev = em.impute_table(feature_vectors_dev, \n",
    "                exclude_attrs=['_id', 'ltable.id', 'rtable.id', 'gold'],\n",
    "                strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cross validation to find if there is a better matcher\n",
    "result = em.select_matcher([dt, rf, svm, nb, lg, ln], table=feature_vectors_dev, \n",
    "        exclude_attrs=['_id', 'ltable.id', 'rtable.id', 'gold'],\n",
    "        k=10,\n",
    "        target_attr='gold', \n",
    "        metric_to_select_matcher='precision',\n",
    "        random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Matcher</th>\n",
       "      <th>Average precision</th>\n",
       "      <th>Average recall</th>\n",
       "      <th>Average f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.981746</td>\n",
       "      <td>0.987134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.964150</td>\n",
       "      <td>0.901706</td>\n",
       "      <td>0.929124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970992</td>\n",
       "      <td>0.985044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.979737</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.976707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>0.981344</td>\n",
       "      <td>0.987302</td>\n",
       "      <td>0.984071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Matcher  Average precision  Average recall  Average f1\n",
       "0  DecisionTree           0.993333        0.981746    0.987134\n",
       "1            RF           1.000000        1.000000    1.000000\n",
       "2           SVM           0.964150        0.901706    0.929124\n",
       "3            NB           1.000000        0.970992    0.985044\n",
       "4        LogReg           0.979737        0.976190    0.976707\n",
       "5        LinReg           0.981344        0.987302    0.984071"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['cv_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Matcher</th>\n",
       "      <th>Num folds</th>\n",
       "      <th>Fold 1</th>\n",
       "      <th>Fold 2</th>\n",
       "      <th>Fold 3</th>\n",
       "      <th>Fold 4</th>\n",
       "      <th>Fold 5</th>\n",
       "      <th>Fold 6</th>\n",
       "      <th>Fold 7</th>\n",
       "      <th>Fold 8</th>\n",
       "      <th>Fold 9</th>\n",
       "      <th>Fold 10</th>\n",
       "      <th>Mean score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>&lt;py_entitymatching.matcher.dtmatcher.DTMatcher object at 0x7f95caa34710&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>&lt;py_entitymatching.matcher.rfmatcher.RFMatcher object at 0x7f95caa347f0&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>&lt;py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0x7f95caa34748&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.964150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB</td>\n",
       "      <td>&lt;py_entitymatching.matcher.nbmatcher.NBMatcher object at 0x7f95caa34860&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0x7f95caa34908&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0x7f95caa34978&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.981344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  \\\n",
       "0  DecisionTree   \n",
       "1            RF   \n",
       "2           SVM   \n",
       "3            NB   \n",
       "4        LogReg   \n",
       "5        LinReg   \n",
       "\n",
       "                                                                            Matcher  \\\n",
       "0          <py_entitymatching.matcher.dtmatcher.DTMatcher object at 0x7f95caa34710>   \n",
       "1          <py_entitymatching.matcher.rfmatcher.RFMatcher object at 0x7f95caa347f0>   \n",
       "2        <py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0x7f95caa34748>   \n",
       "3          <py_entitymatching.matcher.nbmatcher.NBMatcher object at 0x7f95caa34860>   \n",
       "4  <py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0x7f95caa34908>   \n",
       "5  <py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0x7f95caa34978>   \n",
       "\n",
       "   Num folds  Fold 1  Fold 2    Fold 3    Fold 4    Fold 5    Fold 6  Fold 7  \\\n",
       "0         10     1.0     1.0  1.000000  0.933333  1.000000  1.000000     1.0   \n",
       "1         10     1.0     1.0  1.000000  1.000000  1.000000  1.000000     1.0   \n",
       "2         10     1.0     1.0  0.941176  1.000000  1.000000  0.916667     1.0   \n",
       "3         10     1.0     1.0  1.000000  1.000000  1.000000  1.000000     1.0   \n",
       "4         10     1.0     1.0  0.947368  1.000000  0.933333  0.916667     1.0   \n",
       "5         10     1.0     1.0  0.947368  1.000000  1.000000  1.000000     1.0   \n",
       "\n",
       "   Fold 8  Fold 9   Fold 10  Mean score  \n",
       "0  1.0000     1.0  1.000000    0.993333  \n",
       "1  1.0000     1.0  1.000000    1.000000  \n",
       "2  0.9375     1.0  0.846154    0.964150  \n",
       "3  1.0000     1.0  1.000000    1.000000  \n",
       "4  1.0000     1.0  1.000000    0.979737  \n",
       "5  0.9375     1.0  0.928571    0.981344  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['drill_down_cv_stats']['precision']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, observe the best matcher is achieving the expected precision and we can proceed on to evaluating the best matcher on the unseen data (the evaluation set).\n",
    "\n",
    "## 3.4 Evaluating the matching output\n",
    "\n",
    "Evaluating the matching outputs for the evaluation set typically involves the following four steps:\n",
    "\n",
    "1. Extracting the feature vectors\n",
    "2. Training matcher using the feature vectors extracted from the development set\n",
    "3. Predicting the evaluation set using the trained matcher\n",
    "4. Evaluating the predicted matches\n",
    "\n",
    "### 3.4.1 Extracting the feature vectors\n",
    "\n",
    "As before, we extract the feature vectors (using the updated feature table and the evaluation set) and impute it (if necessary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Get new set of features\n",
    "feature_vectors_eval = em.extract_feature_vecs(evaluation, \n",
    "                                               feature_table=feature_subset_iter2, \n",
    "                                               attrs_after='gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the feature vectors contain missing values\n",
    "# A return value of True means that there are missing values\n",
    "any(pd.isnull(feature_vectors_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute feature vectors\n",
    "feature_vectors_eval = em.impute_table(feature_vectors_eval, \n",
    "                exclude_attrs=['_id', 'ltable.id', 'rtable.id', 'gold'],\n",
    "                strategy='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Training the matcher\n",
    "\n",
    "Now, we train the matcher using all of the feature vectors from the development set. For the purposes of this guide we use random forest as the selected matcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train using feature vectors from the development set\n",
    "rf.fit(table=feature_vectors_dev, \n",
    "       exclude_attrs=['_id', 'ltable.id', 'rtable.id', 'gold'], \n",
    "       target_attr='gold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3 Predicting the matches\n",
    "\n",
    "Next, we predict the matches for the evaluation set (using the feature vectors extracted from it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict M \n",
    "predictions = rf.predict(table=feature_vectors_eval, \n",
    "                         exclude_attrs=['_id', 'ltable.id', 'rtable.id', 'gold'], \n",
    "                         append=True, \n",
    "                         target_attr='predicted', \n",
    "                         inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.4 Evaluating the matching output\n",
    "\n",
    "Finally, we evaluate the predicted outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 96.88% (62/64)\n",
      "Recall : 100.0% (62/62)\n",
      "F1 : 98.41%\n",
      "False positives : 2 (out of 64 positive predictions)\n",
      "False negatives : 0 (out of 61 negative predictions)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the result\n",
    "eval_result = em.eval_matches(predictions, 'gold', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
