{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This IPython notebook illustrates how to generate features for blocking/matching manually.\n",
    "\n",
    "First, we need to import *py_entitymatching* package and other libraries as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import py_entitymatching package\n",
    "import py_entitymatching as em\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, read the (sample) input tables for blocking purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the datasets directory\n",
    "datasets_dir = em.get_install_path() + os.sep + 'datasets'\n",
    "\n",
    "# Get the paths of the input tables\n",
    "path_A = datasets_dir + os.sep + 'person_table_A.csv'\n",
    "path_B = datasets_dir + os.sep + 'person_table_B.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the CSV files and set 'ID' as the key attribute\n",
    "A = em.read_csv_metadata(path_A, key='ID')\n",
    "B = em.read_csv_metadata(path_B, key='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Features for Manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Attribute Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atypes1 = em.get_attr_types(A)\n",
    "atypes2 = em.get_attr_types(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'zipcode', 'hourly_wage', 'address', '_table', 'ID', 'birth_year']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atypes1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('numeric', 'numeric', 'str_bt_1w_5w', 'str_bt_1w_5w', 'numeric')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atypes1['birth_year'], atypes1['hourly_wage'], atypes1['address'], atypes1['name'], atypes1['zipcode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('numeric', 'numeric', 'str_bt_5w_10w', 'str_bt_1w_5w', 'numeric')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atypes2['birth_year'], atypes2['hourly_wage'], atypes2['address'], atypes2['name'], atypes2['zipcode']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Attribute Correspondences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "block_c = em.get_attr_corres(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rtable', 'corres', 'ltable']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_c.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4586528400, 4586528400, 4586528592, 4586528592)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(A), id(block_c['ltable']), id(B), id(block_c['rtable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ID', 'ID'),\n",
       " ('name', 'name'),\n",
       " ('birth_year', 'birth_year'),\n",
       " ('hourly_wage', 'hourly_wage'),\n",
       " ('address', 'address'),\n",
       " ('zipcode', 'zipcode')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_c['corres']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for blocking\n",
    "tok = em.get_tokenizers_for_blocking()\n",
    "# for matching\n",
    "# tok = em.get_tokenizers_for_matching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alphabetic': <function py_entitymatching.feature.tokenizers.tok_alphabetic>,\n",
       " 'alphanumeric': <function py_entitymatching.feature.tokenizers.tok_alphanumeric>,\n",
       " 'dlm_dc0': <function py_entitymatching.feature.tokenizers.tok_delim>,\n",
       " 'qgm_2': <function py_entitymatching.feature.tokenizers.tok_qgram>,\n",
       " 'qgm_3': <function py_entitymatching.feature.tokenizers.tok_qgram>,\n",
       " 'wspace': <function py_entitymatching.feature.tokenizers.tok_wspace>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Similarity Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for blocking\n",
    "sim = em.get_sim_funs_for_blocking()\n",
    "\n",
    "# for matching\n",
    "# sim = em.get_sim_funs_for_matching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abs_norm': <function py_entitymatching.feature.simfunctions.abs_norm>,\n",
       " 'affine': <function py_entitymatching.feature.simfunctions.affine>,\n",
       " 'cosine': <function py_entitymatching.feature.simfunctions.cosine>,\n",
       " 'dice': <function py_entitymatching.feature.simfunctions.dice>,\n",
       " 'exact_match': <function py_entitymatching.feature.simfunctions.exact_match>,\n",
       " 'hamming_dist': <function py_entitymatching.feature.simfunctions.hamming_dist>,\n",
       " 'hamming_sim': <function py_entitymatching.feature.simfunctions.hamming_sim>,\n",
       " 'jaccard': <function py_entitymatching.feature.simfunctions.jaccard>,\n",
       " 'jaro': <function py_entitymatching.feature.simfunctions.jaro>,\n",
       " 'jaro_winkler': <function py_entitymatching.feature.simfunctions.jaro_winkler>,\n",
       " 'lev_dist': <function py_entitymatching.feature.simfunctions.lev_dist>,\n",
       " 'lev_sim': <function py_entitymatching.feature.simfunctions.lev_sim>,\n",
       " 'monge_elkan': <function py_entitymatching.feature.simfunctions.monge_elkan>,\n",
       " 'needleman_wunsch': <function py_entitymatching.feature.simfunctions.needleman_wunsch>,\n",
       " 'overlap_coeff': <function py_entitymatching.feature.simfunctions.overlap_coeff>,\n",
       " 'rel_diff': <function py_entitymatching.feature.simfunctions.rel_diff>,\n",
       " 'smith_waterman': <function py_entitymatching.feature.simfunctions.smith_waterman>}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_table = em.get_features(A, B, atypes1, atypes2, block_c, tok, sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>left_attribute</th>\n",
       "      <th>right_attribute</th>\n",
       "      <th>left_attr_tokenizer</th>\n",
       "      <th>right_attr_tokenizer</th>\n",
       "      <th>simfunction</th>\n",
       "      <th>function</th>\n",
       "      <th>function_source</th>\n",
       "      <th>is_auto_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_ID_lev_dist</td>\n",
       "      <td>ID</td>\n",
       "      <td>ID</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>lev_dist</td>\n",
       "      <td>&lt;function ID_ID_lev_dist at 0x111615c08&gt;</td>\n",
       "      <td>from py_entitymatching.feature.simfunctions import *\\nfrom py_entitymatching.feature.tokenizers ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_ID_lev_sim</td>\n",
       "      <td>ID</td>\n",
       "      <td>ID</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>lev_sim</td>\n",
       "      <td>&lt;function ID_ID_lev_sim at 0x111615c80&gt;</td>\n",
       "      <td>from py_entitymatching.feature.simfunctions import *\\nfrom py_entitymatching.feature.tokenizers ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_ID_jar</td>\n",
       "      <td>ID</td>\n",
       "      <td>ID</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>jaro</td>\n",
       "      <td>&lt;function ID_ID_jar at 0x111615cf8&gt;</td>\n",
       "      <td>from py_entitymatching.feature.simfunctions import *\\nfrom py_entitymatching.feature.tokenizers ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_ID_jwn</td>\n",
       "      <td>ID</td>\n",
       "      <td>ID</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>jaro_winkler</td>\n",
       "      <td>&lt;function ID_ID_jwn at 0x111615d70&gt;</td>\n",
       "      <td>from py_entitymatching.feature.simfunctions import *\\nfrom py_entitymatching.feature.tokenizers ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_ID_exm</td>\n",
       "      <td>ID</td>\n",
       "      <td>ID</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>exact_match</td>\n",
       "      <td>&lt;function ID_ID_exm at 0x111615de8&gt;</td>\n",
       "      <td>from py_entitymatching.feature.simfunctions import *\\nfrom py_entitymatching.feature.tokenizers ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_name left_attribute right_attribute left_attr_tokenizer  \\\n",
       "0  ID_ID_lev_dist             ID              ID                None   \n",
       "1   ID_ID_lev_sim             ID              ID                None   \n",
       "2       ID_ID_jar             ID              ID                None   \n",
       "3       ID_ID_jwn             ID              ID                None   \n",
       "4       ID_ID_exm             ID              ID                None   \n",
       "\n",
       "  right_attr_tokenizer   simfunction  \\\n",
       "0                 None      lev_dist   \n",
       "1                 None       lev_sim   \n",
       "2                 None          jaro   \n",
       "3                 None  jaro_winkler   \n",
       "4                 None   exact_match   \n",
       "\n",
       "                                   function  \\\n",
       "0  <function ID_ID_lev_dist at 0x111615c08>   \n",
       "1   <function ID_ID_lev_sim at 0x111615c80>   \n",
       "2       <function ID_ID_jar at 0x111615cf8>   \n",
       "3       <function ID_ID_jwn at 0x111615d70>   \n",
       "4       <function ID_ID_exm at 0x111615de8>   \n",
       "\n",
       "                                                                                       function_source  \\\n",
       "0  from py_entitymatching.feature.simfunctions import *\\nfrom py_entitymatching.feature.tokenizers ...   \n",
       "1  from py_entitymatching.feature.simfunctions import *\\nfrom py_entitymatching.feature.tokenizers ...   \n",
       "2  from py_entitymatching.feature.simfunctions import *\\nfrom py_entitymatching.feature.tokenizers ...   \n",
       "3  from py_entitymatching.feature.simfunctions import *\\nfrom py_entitymatching.feature.tokenizers ...   \n",
       "4  from py_entitymatching.feature.simfunctions import *\\nfrom py_entitymatching.feature.tokenizers ...   \n",
       "\n",
       "   is_auto_generated  \n",
       "0               True  \n",
       "1               True  \n",
       "2               True  \n",
       "3               True  \n",
       "4               True  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(feature_table)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
