{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autotime\n",
    "import sys\n",
    "# sys.path.append('/Users/pradap/Documents/Research/Python-Package/anhaid/magellan/')\n",
    "sys.path.append('/scratch/pradap/python-work/anhaidgroup/py_entitymatching/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This quickstart guide explains how to match two tables using Magellan. Our goal is to come up with a workflow to match DBLP and ACM datasets. Specifically, we want to achieve precision greater than 95% and get recall as high as possible. The datasets contain information about the conference papers published in top databse conferences. \n",
    "\n",
    "First, we need to import the Magellan package as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.18 s\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import py_entitymatching as em\n",
    "import pandas as pd\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version: 3.5.2 |Anaconda 4.1.1 (64-bit)| (default, Jul  2 2016, 17:53:06) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "pandas version: 0.18.1\n",
      "magellan version: 0.1.0\n",
      "time: 1.36 ms\n"
     ]
    }
   ],
   "source": [
    "print('python version: ' + sys.version )\n",
    "print('pandas version: ' + pd.__version__ )\n",
    "print('magellan version: ' + em.__version__ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching two tables typically consists of the following three steps:\n",
    "1. Loading the input tables\n",
    "2. Blocking the input tables to get a candidate set\n",
    "3. Matching the tuple pairs in the candidate set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading the input tables\n",
    "\n",
    "We begin by loading the input tables. For the purpose of this guide, we use the datasets that are included with the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 76.8 ms\n"
     ]
    }
   ],
   "source": [
    "dblp_dataset_path = os.sep.join(['DBLP_ACM', 'DBLP_cleaned.csv'])\n",
    "acm_dataset_path = os.sep.join(['DBLP_ACM', 'ACM_cleaned.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 130 ms\n"
     ]
    }
   ],
   "source": [
    "# Load csv files as dataframes and set the key attribute in the dataframe\n",
    "A = em.read_csv_metadata(dblp_dataset_path, key='id')\n",
    "B = em.read_csv_metadata(acm_dataset_path, key='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tuples in A: 2616\n",
      "Number of tuples in B: 2294\n",
      "Number of tuples in A X B (i.e the cartesian product): 6001104\n",
      "time: 63.6 ms\n"
     ]
    }
   ],
   "source": [
    "print('Number of tuples in A: ' + str(len(A)))\n",
    "print('Number of tuples in B: ' + str(len(B)))\n",
    "print('Number of tuples in A X B (i.e the cartesian product): ' + str(len(A)*len(B)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>journals/sigmod/Mackay99</td>\n",
       "      <td>Semantic Integration of Environmental Models for Application to Global Information Systems and D...</td>\n",
       "      <td>D. Scott Mackay</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conf/vldb/PoosalaI96</td>\n",
       "      <td>Estimation of Query-Result Distribution and its Application in Parallel-Join Load Balancing</td>\n",
       "      <td>Viswanath Poosala, Yannis E. Ioannidis</td>\n",
       "      <td>VLDB</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0  journals/sigmod/Mackay99   \n",
       "1      conf/vldb/PoosalaI96   \n",
       "\n",
       "                                                                                                 title  \\\n",
       "0  Semantic Integration of Environmental Models for Application to Global Information Systems and D...   \n",
       "1          Estimation of Query-Result Distribution and its Application in Parallel-Join Load Balancing   \n",
       "\n",
       "                                  authors          venue  year  \n",
       "0                         D. Scott Mackay  SIGMOD Record  1999  \n",
       "1  Viswanath Poosala, Yannis E. Ioannidis           VLDB  1996  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 115 ms\n"
     ]
    }
   ],
   "source": [
    "A.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>304586</td>\n",
       "      <td>The WASA2 object-oriented workflow management system</td>\n",
       "      <td>Gottfried Vossen, Mathias Weske</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>304587</td>\n",
       "      <td>A user-centered interface for querying distributed multimedia databases</td>\n",
       "      <td>Isabel F. Cruz, Kimberly M. James</td>\n",
       "      <td>International Conference on Management of Data</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  \\\n",
       "0  304586   \n",
       "1  304587   \n",
       "\n",
       "                                                                     title  \\\n",
       "0                     The WASA2 object-oriented workflow management system   \n",
       "1  A user-centered interface for querying distributed multimedia databases   \n",
       "\n",
       "                             authors  \\\n",
       "0    Gottfried Vossen, Mathias Weske   \n",
       "1  Isabel F. Cruz, Kimberly M. James   \n",
       "\n",
       "                                            venue  year  \n",
       "0  International Conference on Management of Data  1999  \n",
       "1  International Conference on Management of Data  1999  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 65.7 ms\n"
     ]
    }
   ],
   "source": [
    "B.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('id', 'id')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 74.5 ms\n"
     ]
    }
   ],
   "source": [
    "# Display the key attributes of table A and B.\n",
    "em.get_key(A), em.get_key(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 934 ms\n"
     ]
    }
   ],
   "source": [
    "# If the tables are large we can downsample the tables like this\n",
    "A1, B1 = em.down_sample(A, B, 500, 1)\n",
    "# But for the demo, we will use the entire table A and B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Blocking to create candidate tuple pairs\n",
    "\n",
    "Before we do the matching, we would like to remove the obviously non-matching tuple pairs from the input tables. This would reduce the number of tuple pairs considered for matching. \n",
    "\n",
    "Magellan provides four different blockers: (1) attribute equivalence, (2) overlap, (3) rule-based, and (4) black-box. Refer to [api reference] for more details. The user can mix and match these blockers to form a blocking sequence \n",
    "applied to input tables.\n",
    "\n",
    "For the matching problem at hand, we know that two conference papers published in different years cannot match. So, we decide to apply an attribute equivelance blocker on the 'year' attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 579 Âµs\n"
     ]
    }
   ],
   "source": [
    "# Plan\n",
    "# A, B ------ attribute equivalence [year] -----> C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 231 ms\n"
     ]
    }
   ],
   "source": [
    "# Create attribute equivalence blocker\n",
    "ab = em.AttrEquivalenceBlocker()\n",
    "# Block tables using 'year' attribute: same year then include in the canidate set\n",
    "C1 = ab.block_tables(A, B, 'year', 'year', \n",
    "                   l_output_attrs=['title', 'authors', 'year'],\n",
    "                   r_output_attrs=['title', 'authors', 'year']\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "601284"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.24 ms\n"
     ]
    }
   ],
   "source": [
    "# Check the number of rows in C1\n",
    "len(C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>ltable_id</th>\n",
       "      <th>rtable_id</th>\n",
       "      <th>ltable_title</th>\n",
       "      <th>ltable_authors</th>\n",
       "      <th>ltable_year</th>\n",
       "      <th>rtable_title</th>\n",
       "      <th>rtable_authors</th>\n",
       "      <th>rtable_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>journals/sigmod/Mackay99</td>\n",
       "      <td>304586</td>\n",
       "      <td>Semantic Integration of Environmental Models for Application to Global Information Systems and D...</td>\n",
       "      <td>D. Scott Mackay</td>\n",
       "      <td>1999</td>\n",
       "      <td>The WASA2 object-oriented workflow management system</td>\n",
       "      <td>Gottfried Vossen, Mathias Weske</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>journals/sigmod/Mackay99</td>\n",
       "      <td>304587</td>\n",
       "      <td>Semantic Integration of Environmental Models for Application to Global Information Systems and D...</td>\n",
       "      <td>D. Scott Mackay</td>\n",
       "      <td>1999</td>\n",
       "      <td>A user-centered interface for querying distributed multimedia databases</td>\n",
       "      <td>Isabel F. Cruz, Kimberly M. James</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id                 ltable_id  rtable_id  \\\n",
       "0    0  journals/sigmod/Mackay99     304586   \n",
       "1    1  journals/sigmod/Mackay99     304587   \n",
       "\n",
       "                                                                                          ltable_title  \\\n",
       "0  Semantic Integration of Environmental Models for Application to Global Information Systems and D...   \n",
       "1  Semantic Integration of Environmental Models for Application to Global Information Systems and D...   \n",
       "\n",
       "    ltable_authors  ltable_year  \\\n",
       "0  D. Scott Mackay         1999   \n",
       "1  D. Scott Mackay         1999   \n",
       "\n",
       "                                                              rtable_title  \\\n",
       "0                     The WASA2 object-oriented workflow management system   \n",
       "1  A user-centered interface for querying distributed multimedia databases   \n",
       "\n",
       "                      rtable_authors  rtable_year  \n",
       "0    Gottfried Vossen, Mathias Weske         1999  \n",
       "1  Isabel F. Cruz, Kimberly M. James         1999  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 169 ms\n"
     ]
    }
   ],
   "source": [
    "# Display first two rows from C1\n",
    "C1.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of tuple pairs considered for matching is reduced to 601284 (from 6001104), but we would want to make sure that the blocker did not drop any potential matches. We could debug the blocker output in Magellan as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.93 s\n"
     ]
    }
   ],
   "source": [
    "# Debug blocker output\n",
    "dbg = em.debug_blocker(C1, A, B, output_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>ltable_id</th>\n",
       "      <th>rtable_id</th>\n",
       "      <th>ltable_title</th>\n",
       "      <th>ltable_authors</th>\n",
       "      <th>ltable_venue</th>\n",
       "      <th>rtable_title</th>\n",
       "      <th>rtable_authors</th>\n",
       "      <th>rtable_venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>journals/sigmod/Aberer02</td>\n",
       "      <td>776994</td>\n",
       "      <td>Book Review Column</td>\n",
       "      <td>Karl Aberer</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>Book review column</td>\n",
       "      <td>Karl Aberer</td>\n",
       "      <td>ACM SIGMOD Record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.875</td>\n",
       "      <td>journals/sigmod/Aberer02a</td>\n",
       "      <td>776994</td>\n",
       "      <td>Book Review Column</td>\n",
       "      <td>Karl Aberer</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>Book review column</td>\n",
       "      <td>Karl Aberer</td>\n",
       "      <td>ACM SIGMOD Record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.875</td>\n",
       "      <td>journals/sigmod/Aberer02b</td>\n",
       "      <td>604274</td>\n",
       "      <td>Book Review Column</td>\n",
       "      <td>Karl Aberer</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>Book review column</td>\n",
       "      <td>Karl Aberer</td>\n",
       "      <td>ACM SIGMOD Record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.875</td>\n",
       "      <td>journals/sigmod/Aberer03b</td>\n",
       "      <td>601865</td>\n",
       "      <td>Book review column</td>\n",
       "      <td>Karl Aberer</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>Book review column</td>\n",
       "      <td>Karl Aberer</td>\n",
       "      <td>ACM SIGMOD Record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.875</td>\n",
       "      <td>journals/sigmod/Aberer02</td>\n",
       "      <td>604274</td>\n",
       "      <td>Book Review Column</td>\n",
       "      <td>Karl Aberer</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>Book review column</td>\n",
       "      <td>Karl Aberer</td>\n",
       "      <td>ACM SIGMOD Record</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id  similarity                  ltable_id  rtable_id        ltable_title  \\\n",
       "0    0       0.875   journals/sigmod/Aberer02     776994  Book Review Column   \n",
       "1    1       0.875  journals/sigmod/Aberer02a     776994  Book Review Column   \n",
       "2    2       0.875  journals/sigmod/Aberer02b     604274  Book Review Column   \n",
       "3    3       0.875  journals/sigmod/Aberer03b     601865  Book review column   \n",
       "4    4       0.875   journals/sigmod/Aberer02     604274  Book Review Column   \n",
       "\n",
       "  ltable_authors   ltable_venue        rtable_title rtable_authors  \\\n",
       "0    Karl Aberer  SIGMOD Record  Book review column    Karl Aberer   \n",
       "1    Karl Aberer  SIGMOD Record  Book review column    Karl Aberer   \n",
       "2    Karl Aberer  SIGMOD Record  Book review column    Karl Aberer   \n",
       "3    Karl Aberer  SIGMOD Record  Book review column    Karl Aberer   \n",
       "4    Karl Aberer  SIGMOD Record  Book review column    Karl Aberer   \n",
       "\n",
       "        rtable_venue  \n",
       "0  ACM SIGMOD Record  \n",
       "1  ACM SIGMOD Record  \n",
       "2  ACM SIGMOD Record  \n",
       "3  ACM SIGMOD Record  \n",
       "4  ACM SIGMOD Record  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.9 ms\n"
     ]
    }
   ],
   "source": [
    "# Display first few tuple pairs from the debug_blocker's output\n",
    "dbg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the debug blocker's output we observe that the current blocker drops quite a few potential matches. We would want to update the blocking sequence to avoid dropping these potential matches.\n",
    "\n",
    "For the considered dataset, we know that for the conference papers to match the author names must overlap between them. We could use overlap blocker for this purpose. Finally, we would want to union the outputs from the attribute equivalence blocker and the overlap blocker to get a consolidated candidate set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 594 ms\n"
     ]
    }
   ],
   "source": [
    "# Updated blocking sequence\n",
    "# A, B ------ attribute equivalence [year] -----> C1--\n",
    "#                                                     |----> C\n",
    "# A, B ------ overlap blocker [authors] --------> C2--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.62 s\n"
     ]
    }
   ],
   "source": [
    "# Create an overlap blocker\n",
    "ob = em.OverlapBlocker()\n",
    "# Apply overlap blocker on 'authors' attribute\n",
    "C2 = ob.block_tables(A, B, 'authors', 'authors', \n",
    "                   l_output_attrs=['title', 'authors', 'year'],\n",
    "                   r_output_attrs=['title', 'authors', 'year']\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287414"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.82 ms\n"
     ]
    }
   ],
   "source": [
    "# Check the number of rows in C2\n",
    "len(C2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>ltable_id</th>\n",
       "      <th>rtable_id</th>\n",
       "      <th>ltable_title</th>\n",
       "      <th>ltable_authors</th>\n",
       "      <th>ltable_year</th>\n",
       "      <th>rtable_title</th>\n",
       "      <th>rtable_authors</th>\n",
       "      <th>rtable_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>journals/tods/LechtenborgerV03</td>\n",
       "      <td>304586</td>\n",
       "      <td>On the computation of relational view complements</td>\n",
       "      <td>lechtenbrger vossen jens gottfried</td>\n",
       "      <td>2003</td>\n",
       "      <td>The WASA2 object-oriented workflow management system</td>\n",
       "      <td>vossen weske mathias gottfried</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>conf/sigmod/VossenW99</td>\n",
       "      <td>304586</td>\n",
       "      <td>The WASA2 Object-Oriented Workflow Management System</td>\n",
       "      <td>vossen weske mathias gottfried</td>\n",
       "      <td>1999</td>\n",
       "      <td>The WASA2 object-oriented workflow management system</td>\n",
       "      <td>vossen weske mathias gottfried</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id                       ltable_id  rtable_id  \\\n",
       "0    0  journals/tods/LechtenborgerV03     304586   \n",
       "1    1           conf/sigmod/VossenW99     304586   \n",
       "\n",
       "                                           ltable_title  \\\n",
       "0     On the computation of relational view complements   \n",
       "1  The WASA2 Object-Oriented Workflow Management System   \n",
       "\n",
       "                       ltable_authors  ltable_year  \\\n",
       "0  lechtenbrger vossen jens gottfried         2003   \n",
       "1      vossen weske mathias gottfried         1999   \n",
       "\n",
       "                                           rtable_title  \\\n",
       "0  The WASA2 object-oriented workflow management system   \n",
       "1  The WASA2 object-oriented workflow management system   \n",
       "\n",
       "                   rtable_authors  rtable_year  \n",
       "0  vossen weske mathias gottfried         1999  \n",
       "1  vossen weske mathias gottfried         1999  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 209 ms\n"
     ]
    }
   ],
   "source": [
    "# Display first two rows from C2\n",
    "C2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 815 ms\n"
     ]
    }
   ],
   "source": [
    "# Combine blocker outputs\n",
    "C = em.combine_blocker_outputs_via_union([C1, C2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "857777"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.79 ms\n"
     ]
    }
   ],
   "source": [
    "# Check the number of rows in the consolidated candidate set.\n",
    "len(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the number of tuple pairs considered for matching is increased to 875758 (from 601284). Now let us debug the blocker output again to check if the current blocker sequence is dropping any potential matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.78 s\n"
     ]
    }
   ],
   "source": [
    "# Debug again\n",
    "dbg = em.debug_blocker(C, A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>ltable_id</th>\n",
       "      <th>rtable_id</th>\n",
       "      <th>ltable_title</th>\n",
       "      <th>ltable_authors</th>\n",
       "      <th>ltable_venue</th>\n",
       "      <th>rtable_title</th>\n",
       "      <th>rtable_authors</th>\n",
       "      <th>rtable_venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>journals/sigmod/Dogac98</td>\n",
       "      <td>945727</td>\n",
       "      <td>Guest Editor's Introduction</td>\n",
       "      <td>Asuman Dogac</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>Guest editor's introduction</td>\n",
       "      <td>Karl Aberer</td>\n",
       "      <td>ACM SIGMOD Record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>journals/sigmod/Dogac02</td>\n",
       "      <td>945727</td>\n",
       "      <td>Guest Editor's Introduction</td>\n",
       "      <td>Asuman Dogac</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>Guest editor's introduction</td>\n",
       "      <td>Karl Aberer</td>\n",
       "      <td>ACM SIGMOD Record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>journals/sigmod/Snodgrass98a</td>\n",
       "      <td>641001</td>\n",
       "      <td>Reminiscences on Influential Papers</td>\n",
       "      <td>Richard T. Snodgrass</td>\n",
       "      <td>SIGMOD Record</td>\n",
       "      <td>Reminiscences on influential papers</td>\n",
       "      <td>Kenneth A. Ross</td>\n",
       "      <td>ACM SIGMOD Record</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id  similarity                     ltable_id  rtable_id  \\\n",
       "0    0    0.500000       journals/sigmod/Dogac98     945727   \n",
       "1    1    0.500000       journals/sigmod/Dogac02     945727   \n",
       "2    2    0.461538  journals/sigmod/Snodgrass98a     641001   \n",
       "\n",
       "                          ltable_title        ltable_authors   ltable_venue  \\\n",
       "0          Guest Editor's Introduction          Asuman Dogac  SIGMOD Record   \n",
       "1          Guest Editor's Introduction          Asuman Dogac  SIGMOD Record   \n",
       "2  Reminiscences on Influential Papers  Richard T. Snodgrass  SIGMOD Record   \n",
       "\n",
       "                          rtable_title   rtable_authors       rtable_venue  \n",
       "0          Guest editor's introduction      Karl Aberer  ACM SIGMOD Record  \n",
       "1          Guest editor's introduction      Karl Aberer  ACM SIGMOD Record  \n",
       "2  Reminiscences on influential papers  Kenneth A. Ross  ACM SIGMOD Record  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.8 ms\n"
     ]
    }
   ],
   "source": [
    "# Display first few rows from the debugger output\n",
    "dbg.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We observe that the current blocker sequence does not drop obvious potential matches, and we can proceed with the matching step now. A subtle point to note here is, debugging blocker output practically provides a stopping criteria for modifying the blocker sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Matching tuple pairs in the candidate set\n",
    "\n",
    "In this step, we would want to match the tuple pairs in the candidate set. Specifically, we use learning-based method for matching purposes.\n",
    "\n",
    "This typically involves the following five steps:\n",
    "\n",
    "1. Sampling and labeling the candidate set\n",
    "2. Splitting the labeled data into development and evaluation set\n",
    "3. Selecting the best learning based matcher using the development set\n",
    "4. Evaluating the selected matcher using the evaluation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Sampling and labeling the candidate set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we randomly sample 450 tuple pairs for labeling purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 361 ms\n"
     ]
    }
   ],
   "source": [
    "# Sample candidate set\n",
    "S = em.sample_table(C, 450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we label the sampled candidate set. Specify we would enter 1 for a match and 0 for a non-match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.73 s\n"
     ]
    }
   ],
   "source": [
    "# Label S and specify the attribute name for the label column\n",
    "L = em.label_table(S, 'gold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this guide, we will load in a pre-labeled dataset (of 415 tuple pairs) included in this package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.12 ms\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-labeled data\n",
    "L = em.read_csv_metadata('DBLP_ACM/dblp_acm_demo_labels.csv', ltable=A, rtable=B)\n",
    "# Display the number of rows in the labaled data set\n",
    "len(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Splitting the labeled data into development and evaluation set\n",
    "\n",
    "In this step, we split the labeled data into two sets: development and evaluation. Specifically, the development set is used to come up with the best learning-based matcher and the evaluation set used to evaluate the selected matcher on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 263 ms\n"
     ]
    }
   ],
   "source": [
    "# Split the labeled data into development and evaluation set\n",
    "development_evaluation = em.split_train_test(L, train_proportion=0.7)\n",
    "development =  development_evaluation['train']\n",
    "evaluation = development_evaluation['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Select the best learning-based matcher\n",
    "\n",
    "Selecting the best learning-based matcher typically involves the following steps:\n",
    "1. Creating a set of learning-based matchers\n",
    "2. Creating features\n",
    "3. Extracting feature vectors\n",
    "4. Selecting the best learning-based matcher using k-fold cross validation\n",
    "5. Debugging the matcher (and possibly repeat the above steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.3.1 Creating a set of learning-based matchers\n",
    "\n",
    "First, we need to create a set of learning-based matchers. The following matchers are supported in Magellan: (1) decision tree, (2) random forest, (3) naive bayes, (4) svm, (5) logistic regression, and (6) linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 742 ms\n"
     ]
    }
   ],
   "source": [
    "# Create a set of ML-matchers\n",
    "dt = em.DTMatcher(name='DecisionTree')\n",
    "svm = em.SVMMatcher(name='SVM')\n",
    "rf = em.RFMatcher(name='RF')\n",
    "nb = em.NBMatcher(name='NB')\n",
    "lg = em.LogRegMatcher(name='LogReg')\n",
    "ln = em.LinRegMatcher(name='LinReg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Creating features\n",
    "\n",
    "Next, we need to create a set of features for the development set. Magellan provides a way to automatically generate features based on the attributes in the input tables. For the purposes of this guide, we use the automatically generated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 810 ms\n"
     ]
    }
   ],
   "source": [
    "# Generate features\n",
    "feature_table = em.get_features_for_matching(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             title_title_jac_qgm_3_qgm_3\n",
       "1         title_title_cos_dlm_dc0_dlm_dc0\n",
       "2                         title_title_mel\n",
       "3                    title_title_lev_dist\n",
       "4                     title_title_lev_sim\n",
       "5         authors_authors_jac_qgm_3_qgm_3\n",
       "6     authors_authors_cos_dlm_dc0_dlm_dc0\n",
       "7                     authors_authors_mel\n",
       "8                authors_authors_lev_dist\n",
       "9                 authors_authors_lev_sim\n",
       "10                          year_year_exm\n",
       "11                          year_year_anm\n",
       "12                     year_year_lev_dist\n",
       "13                      year_year_lev_sim\n",
       "Name: feature_name, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 22 ms\n"
     ]
    }
   ],
   "source": [
    "# List the names of the features generated\n",
    "feature_table['feature_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that there were 14 features generated. As a first step, lets say that we decide to use only 'year' related features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 61.5 ms\n"
     ]
    }
   ],
   "source": [
    "# Select the year related features\n",
    "feature_subset_iter1 = feature_table[10:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10         year_year_exm\n",
       "11         year_year_anm\n",
       "12    year_year_lev_dist\n",
       "13     year_year_lev_sim\n",
       "Name: feature_name, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 73 ms\n"
     ]
    }
   ],
   "source": [
    "# List the names of the features selected\n",
    "feature_subset_iter1['feature_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 Extracting feature vectors\n",
    "\n",
    "In this step, we extract feature vectors using the development set and the created features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 317 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Extract feature vectors\n",
    "feature_vectors_dev = em.extract_feature_vecs(development, \n",
    "                            feature_table=feature_subset_iter1, \n",
    "                            attrs_after='gold')                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>ltable_id</th>\n",
       "      <th>rtable_id</th>\n",
       "      <th>year_year_exm</th>\n",
       "      <th>year_year_anm</th>\n",
       "      <th>year_year_lev_dist</th>\n",
       "      <th>year_year_lev_sim</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>171</td>\n",
       "      <td>conf/vldb/DonjerkovicR99</td>\n",
       "      <td>671510</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>301</td>\n",
       "      <td>journals/sigmod/Hanna95</td>\n",
       "      <td>212001</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>conf/sigmod/NguyenACP01</td>\n",
       "      <td>375723</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     _id                 ltable_id  rtable_id  year_year_exm  year_year_anm  \\\n",
       "171  171  conf/vldb/DonjerkovicR99     671510              1            1.0   \n",
       "301  301   journals/sigmod/Hanna95     212001              1            1.0   \n",
       "91    91   conf/sigmod/NguyenACP01     375723              1            1.0   \n",
       "\n",
       "     year_year_lev_dist  year_year_lev_sim  gold  \n",
       "171                 0.0                1.0     1  \n",
       "301                 0.0                1.0     0  \n",
       "91                  0.0                1.0     1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.7 ms\n"
     ]
    }
   ],
   "source": [
    "# Display first few rows\n",
    "feature_vectors_dev.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we might have to impute the feature vectors as it might contain missing values. First, let us check if there are any missing values in the extracted feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 63.7 ms\n"
     ]
    }
   ],
   "source": [
    "# Check if the feature vectors contain missing values\n",
    "# A return value of True means that there are missing values\n",
    "any(pd.isnull(feature_vectors_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the extracted feature vectors contain missing values. We have to impute the missing values for the learning-based matchers to fit the model correctly. For the purposes of this guide, we impute the missing value in a column with the mean of the values in that column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 85.4 ms\n"
     ]
    }
   ],
   "source": [
    "# Impute feature vectors with the mean of the column values.\n",
    "feature_vectors_dev = em.impute_table(feature_vectors_dev, \n",
    "                exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'gold'],\n",
    "                strategy='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4 Selecting the best matcher using cross-validation\n",
    "\n",
    "Now, we select the best matcher using k-fold cross-validation. For the purposes of this guide, we use five fold cross validation and use 'precision' metric to select the best matcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 272 ms\n"
     ]
    }
   ],
   "source": [
    "# Select the best ML matcher using CV\n",
    "result = em.select_matcher([dt, rf, svm, nb, lg, ln], table=feature_vectors_dev, \n",
    "        exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'gold'],\n",
    "        k=10,\n",
    "        target_attr='gold', metric='precision') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Matcher</th>\n",
       "      <th>Num folds</th>\n",
       "      <th>Fold 1</th>\n",
       "      <th>Fold 2</th>\n",
       "      <th>Fold 3</th>\n",
       "      <th>Fold 4</th>\n",
       "      <th>Fold 5</th>\n",
       "      <th>Fold 6</th>\n",
       "      <th>Fold 7</th>\n",
       "      <th>Fold 8</th>\n",
       "      <th>Fold 9</th>\n",
       "      <th>Fold 10</th>\n",
       "      <th>Mean score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>&lt;py_entitymatching.matcher.dtmatcher.DTMatcher object at 0x7f02d94f6c88&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>&lt;py_entitymatching.matcher.rfmatcher.RFMatcher object at 0x7f02d94f6d68&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>&lt;py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0x7f02d94f6cc0&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.987045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB</td>\n",
       "      <td>&lt;py_entitymatching.matcher.nbmatcher.NBMatcher object at 0x7f02d94f6dd8&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.987868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0x7f02d94f6e80&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0x7f02d94f6ef0&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  \\\n",
       "0  DecisionTree   \n",
       "1            RF   \n",
       "2           SVM   \n",
       "3            NB   \n",
       "4        LogReg   \n",
       "5        LinReg   \n",
       "\n",
       "                                                                            Matcher  \\\n",
       "0          <py_entitymatching.matcher.dtmatcher.DTMatcher object at 0x7f02d94f6c88>   \n",
       "1          <py_entitymatching.matcher.rfmatcher.RFMatcher object at 0x7f02d94f6d68>   \n",
       "2        <py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0x7f02d94f6cc0>   \n",
       "3          <py_entitymatching.matcher.nbmatcher.NBMatcher object at 0x7f02d94f6dd8>   \n",
       "4  <py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0x7f02d94f6e80>   \n",
       "5  <py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0x7f02d94f6ef0>   \n",
       "\n",
       "   Num folds  Fold 1    Fold 2  Fold 3    Fold 4  Fold 5  Fold 6    Fold 7  \\\n",
       "0         10     1.0  1.000000     1.0  1.000000     1.0     1.0  0.937500   \n",
       "1         10     1.0  1.000000     1.0  1.000000     1.0     1.0  0.937500   \n",
       "2         10     1.0  0.923077     1.0  1.000000     1.0     1.0  1.000000   \n",
       "3         10     1.0  1.000000     1.0  0.941176     1.0     1.0  0.937500   \n",
       "4         10     1.0  0.933333     1.0  1.000000     1.0     1.0  0.882353   \n",
       "5         10     1.0  1.000000     1.0  1.000000     1.0     1.0  0.937500   \n",
       "\n",
       "   Fold 8    Fold 9  Fold 10  Mean score  \n",
       "0     1.0  1.000000      1.0    0.993750  \n",
       "1     1.0  0.950000      1.0    0.988750  \n",
       "2     1.0  0.947368      1.0    0.987045  \n",
       "3     1.0  1.000000      1.0    0.987868  \n",
       "4     1.0  0.950000      1.0    0.976569  \n",
       "5     1.0  0.950000      1.0    0.988750  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.6 ms\n"
     ]
    }
   ],
   "source": [
    "# Check the cross validation statistics\n",
    "result['cv_stats']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.5 Debugging matcher\n",
    "\n",
    "We observe that the best matcher is not getting us to the precision that we expect (i.e > 95%). We debug the matcher to see what might be wrong.\n",
    "\n",
    "To do this, first we split the feature vectors into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 526 ms\n"
     ]
    }
   ],
   "source": [
    "# # Split feature vectors into train and test\n",
    "train_test = em.split_train_test(feature_vectors_dev, train_proportion=0.5)\n",
    "train = train_test['train']\n",
    "test = train_test['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we debug the matcher using GUI. For the purposes of this guide, we use random forest matcher for debugging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.68 s\n"
     ]
    }
   ],
   "source": [
    "# Debug decision tree using GUI\n",
    "em.vis_debug_rf(rf, train, test, \n",
    "        exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'gold'],\n",
    "        target_attr='gold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the GUI, we observe that using only 'year' related features result in a lot of false positives. So we decide to use all the features in the feature table (which had author, title and year related features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 804 Âµs\n"
     ]
    }
   ],
   "source": [
    "# Select all features from the feature table\n",
    "feature_subset_iter2 = feature_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we repeat extracting feature vectors (this time with updated feature table), imputing table and selecting the best matcher again using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 691 ms\n"
     ]
    }
   ],
   "source": [
    "# Get new set of features\n",
    "feature_vectors_dev = em.extract_feature_vecs(development, feature_table=feature_subset_iter2, attrs_after='gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.7 ms\n"
     ]
    }
   ],
   "source": [
    "# Check if imputation is required\n",
    "any(pd.isnull(feature_vectors_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 115 ms\n"
     ]
    }
   ],
   "source": [
    "# Impute feature vectors\n",
    "feature_vectors_dev = em.impute_table(feature_vectors_dev, \n",
    "                exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'gold'],\n",
    "                strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 270 ms\n"
     ]
    }
   ],
   "source": [
    "# Apply cross validation to find if there is a better matcher\n",
    "result = em.select_matcher([dt, rf, svm, nb, lg, ln], table=feature_vectors_dev, \n",
    "        exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'gold'],\n",
    "        k=10,\n",
    "        target_attr='gold', metric='f1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Matcher</th>\n",
       "      <th>Num folds</th>\n",
       "      <th>Fold 1</th>\n",
       "      <th>Fold 2</th>\n",
       "      <th>Fold 3</th>\n",
       "      <th>Fold 4</th>\n",
       "      <th>Fold 5</th>\n",
       "      <th>Fold 6</th>\n",
       "      <th>Fold 7</th>\n",
       "      <th>Fold 8</th>\n",
       "      <th>Fold 9</th>\n",
       "      <th>Fold 10</th>\n",
       "      <th>Mean score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>&lt;py_entitymatching.matcher.dtmatcher.DTMatcher object at 0x7f02d94f6c88&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>0.97561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.983930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>&lt;py_entitymatching.matcher.rfmatcher.RFMatcher object at 0x7f02d94f6d68&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>0.97561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.97561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>&lt;py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0x7f02d94f6cc0&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.936074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB</td>\n",
       "      <td>&lt;py_entitymatching.matcher.nbmatcher.NBMatcher object at 0x7f02d94f6dd8&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>0.97561</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0x7f02d94f6e80&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>0.97561</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.97561</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.976537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0x7f02d94f6ef0&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.97561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  \\\n",
       "0  DecisionTree   \n",
       "1            RF   \n",
       "2           SVM   \n",
       "3            NB   \n",
       "4        LogReg   \n",
       "5        LinReg   \n",
       "\n",
       "                                                                            Matcher  \\\n",
       "0          <py_entitymatching.matcher.dtmatcher.DTMatcher object at 0x7f02d94f6c88>   \n",
       "1          <py_entitymatching.matcher.rfmatcher.RFMatcher object at 0x7f02d94f6d68>   \n",
       "2        <py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0x7f02d94f6cc0>   \n",
       "3          <py_entitymatching.matcher.nbmatcher.NBMatcher object at 0x7f02d94f6dd8>   \n",
       "4  <py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0x7f02d94f6e80>   \n",
       "5  <py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0x7f02d94f6ef0>   \n",
       "\n",
       "   Num folds   Fold 1    Fold 2  Fold 3    Fold 4    Fold 5    Fold 6  \\\n",
       "0         10  0.97561  1.000000     1.0  1.000000  0.972973  1.000000   \n",
       "1         10  0.97561  1.000000     1.0  1.000000  0.972973  1.000000   \n",
       "2         10  0.95000  0.928571     1.0  0.916667  0.944444  0.888889   \n",
       "3         10  0.97561  0.967742     1.0  1.000000  0.972973  1.000000   \n",
       "4         10  0.97561  0.937500     1.0  0.962963  0.972973  1.000000   \n",
       "5         10  1.00000  1.000000     1.0  1.000000  0.972973  1.000000   \n",
       "\n",
       "     Fold 7    Fold 8   Fold 9   Fold 10  Mean score  \n",
       "0  0.972973  1.000000  0.95000  0.967742    0.983930  \n",
       "1  0.972973  1.000000  0.97561  1.000000    0.989717  \n",
       "2  0.941176  0.944444  0.95000  0.896552    0.936074  \n",
       "3  0.972973  1.000000  1.00000  1.000000    0.988930  \n",
       "4  0.972973  1.000000  0.97561  0.967742    0.976537  \n",
       "5  0.972973  1.000000  0.97561  1.000000    0.992156  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 18.1 ms\n"
     ]
    }
   ],
   "source": [
    "result['cv_stats']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, observe the best matcher is achieving the expected precision and we can proceed on to evaluating the best matcher on the unseen data (the evaluation set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Evaluating the matching output\n",
    "\n",
    "Evaluating the matching outputs for the evaluation set typically involves the following four steps:\n",
    "1. Extracting the feature vectors\n",
    "2. Training matcher using the feature vectors extracted from the development set\n",
    "3. Predicting the evaluation set using the trained matcher\n",
    "4. Evaluating the predicted matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Extracting the feature vectors\n",
    "\n",
    "As before, we extract the feature vectors (using the updated feature table and the evaluation set) and impute it (if necessary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 430 ms\n"
     ]
    }
   ],
   "source": [
    "# Get new set of features\n",
    "feature_vectors_eval = em.extract_feature_vecs(evaluation, \n",
    "                                               feature_table=feature_subset_iter2, \n",
    "                                               attrs_after='gold')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.75 ms\n"
     ]
    }
   ],
   "source": [
    "# Check if the feature vectors contain missing values\n",
    "# A return value of True means that there are missing values\n",
    "any(pd.isnull(feature_vectors_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 82.2 ms\n"
     ]
    }
   ],
   "source": [
    "# Impute feature vectors\n",
    "feature_vectors_eval = em.impute_table(feature_vectors_eval, \n",
    "                exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'gold'],\n",
    "                strategy='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Training the matcher\n",
    "\n",
    "Now, we train the matcher using all of the feature vectors from the development set. For the purposes of this guide we use random forest as the selected matcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 124 ms\n"
     ]
    }
   ],
   "source": [
    "# Train using feature vectors from the development set\n",
    "rf.fit(table=feature_vectors_dev, \n",
    "       exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'gold'], \n",
    "       target_attr='gold')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3 Predicting the matches\n",
    "Next, we predict the matches for the evaluation set (using the feature vectors extracted from it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 74.3 ms\n"
     ]
    }
   ],
   "source": [
    "# Predict M \n",
    "predictions = rf.predict(table=feature_vectors_eval, \n",
    "                         exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'gold'], \n",
    "                         append=True, \n",
    "                         target_attr='predicted', \n",
    "                         inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.4 Evaluating the matching output\n",
    "\n",
    "Finally, we evaluate the predicted outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 98.28% (57/58)\n",
      "Recall : 98.28% (57/58)\n",
      "F1 : 98.28%\n",
      "False positives : 1 (out of 58 positive predictions)\n",
      "False negatives : 1 (out of 67 negative predictions)\n",
      "time: 104 ms\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the result\n",
    "eval_result = em.eval_matches(predictions, 'gold', 'predicted')\n",
    "em.print_eval_summary(eval_result)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
